{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying corrections to columnar data\n",
    "\n",
    "Here we will show how to use the `coffea.lookup_tools` package.\n",
    "It is able to read in a variety of common correction file formats into a standardized lookup table format.\n",
    "We also cover here some CMS-specific tools for jet corrections (`coffea.jetmet_tools`) and b-tagging efficiencies/uncertainties (`coffea.btag_tools`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test data**:\n",
    "We'll use NanoEvents to construct some test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.nanoaod import NanoEvents\n",
    "\n",
    "fname = \"https://github.com/CoffeaTeam/coffea/raw/master/tests/samples/nano_dy.root\"\n",
    "events = NanoEvents.from_file(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entrypoint for `coffea.lookup_tools` is the [extractor class](https://coffeateam.github.io/coffea/api/coffea.lookup_tools.extractor.html#coffea.lookup_tools.extractor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.lookup_tools import extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# download some sample correction sources\n",
    "mkdir -p data\n",
    "pushd data\n",
    "PREFIX=https://raw.githubusercontent.com/CoffeaTeam/coffea/master/tests/samples\n",
    "curl -Os $PREFIX/testSF2d.histo.root\n",
    "curl -Os $PREFIX/testBTagSF.btag.csv\n",
    "curl -Os $PREFIX/EIDISO_WH_out.histo.json\n",
    "curl -Os $PREFIX/Fall17_17Nov2017_V32_MC_L2Relative_AK4PFPuppi.jec.txt\n",
    "curl -Os $PREFIX/Fall17_17Nov2017_V32_MC_Uncertainty_AK4PFPuppi.junc.txt\n",
    "curl -Os $PREFIX/DeepCSV_102XSF_V1.btag.csv.gz\n",
    "popd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening a root file and using it as a lookup table\n",
    "\n",
    "In [tests/samples](https://github.com/CoffeaTeam/coffea/tree/master/tests/samples), there is an example file with a `TH2F` histogram named `scalefactors_Tight_Electron`. The following code reads that histogram into an [evaluator](https://coffeateam.github.io/coffea/api/coffea.lookup_tools.evaluator.html#coffea.lookup_tools.evaluator) instance, under the key `testSF2d` and applies it to some electrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = extractor()\n",
    "# several histograms can be imported at once using wildcards (*)\n",
    "ext.add_weight_sets([\"testSF2d scalefactors_Tight_Electron data/testSF2d.histo.root\"])\n",
    "ext.finalize()\n",
    "\n",
    "evaluator = ext.make_evaluator()\n",
    "\n",
    "print(\"available evaluator keys:\")\n",
    "for key in evaluator.keys():\n",
    "    print(\"\\t\", key)\n",
    "print(\"testSF2d:\", evaluator['testSF2d'])\n",
    "print(\"type of testSF2d:\", type(evaluator['testSF2d']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Electron eta:\", events.Electron.eta)\n",
    "print(\"Electron pt:\", events.Electron.pt)\n",
    "print(\"Scale factor:\", evaluator[\"testSF2d\"](events.Electron.eta, events.Electron.pt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a CMS b-tag scale factor csv file\n",
    "\n",
    "These files have the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -5 data/testBTagSF.btag.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extractor assumes `*.csv` files have this structure and interprets them as so. The resulting scale factors can be used to calculate b-tagging corrections or uncertainties. **Note**: a high-level b-tagging correction class is also available, see the later sections of this guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = extractor()\n",
    "ext.add_weight_sets([\"testBTag * data/testBTagSF.btag.csv\"])\n",
    "ext.finalize()\n",
    "\n",
    "evaluator = ext.make_evaluator()\n",
    "\n",
    "print(\"available evaluator keys:\")\n",
    "for i, key in enumerate(evaluator.keys()):\n",
    "    print(\"\\t\", key)\n",
    "    if i > 5:\n",
    "        print(\"\\t ...\")\n",
    "        break\n",
    "print(\"testBTagCSVv2_1_comb_up_0:\", evaluator['testBTagCSVv2_1_comb_up_0'])\n",
    "print(\"type of testBTagCSVv2_1_comb_up_0:\", type(evaluator['testBTagCSVv2_1_comb_up_0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: in a real situation you would want to apply the SF on the appropriate jet flavor\n",
    "scalefactor = evaluator['testBTagCSVv2_1_comb_up_0'](events.Jet.eta, events.Jet.pt, events.Jet.btagCSVV2)\n",
    "print(scalefactor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing JSON-encoded histograms\n",
    "\n",
    "Some corrections are provided in a json format, with a structure like\n",
    "```\n",
    "data[category][name][axis1 bin][axis2 bin][\"value\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -10 data/EIDISO_WH_out.histo.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extractor assumes `*.json` files follow this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = extractor()\n",
    "ext.add_weight_sets([\"* * data/EIDISO_WH_out.histo.json\"])\n",
    "ext.finalize()\n",
    "    \n",
    "evaluator = ext.make_evaluator()\n",
    "\n",
    "print(\"available evaluator keys:\")\n",
    "for key in evaluator.keys():\n",
    "    print(\"\\t\", key)\n",
    "print(\"EIDISO_WH/eta_pt_ratio_value:\", evaluator['EIDISO_WH/eta_pt_ratio_value'])\n",
    "print(\"type of EIDISO_WH/eta_pt_ratio_value:\", type(evaluator['EIDISO_WH/eta_pt_ratio_value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_out = evaluator['EIDISO_WH/eta_pt_ratio_value'](events.Electron.eta, events.Electron.pt)\n",
    "sf_err_out = evaluator['EIDISO_WH/eta_pt_ratio_error'](events.Electron.eta, events.Electron.pt)\n",
    "print(sf_out)\n",
    "print(sf_err_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import CMS Jet Energy Scales and Uncertainties\n",
    "In CMS, the jet energy scale and resolution corrections, as well as their uncertainties are available in a standalone text file format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -5 data/Fall17_17Nov2017_V32_MC_L2Relative_AK4PFPuppi.jec.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -3 data/Fall17_17Nov2017_V32_MC_Uncertainty_AK4PFPuppi.junc.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extractor assumes files with `*.txt` are to be interpreted as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = extractor()\n",
    "ext.add_weight_sets([\n",
    "    \"* * data/Fall17_17Nov2017_V32_MC_L2Relative_AK4PFPuppi.jec.txt\",\n",
    "    \"* * data/Fall17_17Nov2017_V32_MC_Uncertainty_AK4PFPuppi.junc.txt\",\n",
    "])\n",
    "ext.finalize()\n",
    "\n",
    "evaluator = ext.make_evaluator()\n",
    "\n",
    "print(\"available evaluator keys:\")\n",
    "for key in evaluator.keys():\n",
    "    print(\"\\t\", key)\n",
    "\n",
    "print()\n",
    "print(\"Fall17_17Nov2017_V32_MC_L2Relative_AK4PFPuppi:\")\n",
    "print(evaluator['Fall17_17Nov2017_V32_MC_L2Relative_AK4PFPuppi'])\n",
    "print(\"type of Fall17_17Nov2017_V32_MC_L2Relative_AK4PFPuppi:\")\n",
    "print(type(evaluator['Fall17_17Nov2017_V32_MC_L2Relative_AK4PFPuppi']))\n",
    "print()\n",
    "print(\"Fall17_17Nov2017_V32_MC_Uncertainty_AK4PFPuppi:\")\n",
    "print(evaluator['Fall17_17Nov2017_V32_MC_Uncertainty_AK4PFPuppi'])\n",
    "print(\"type of Fall17_17Nov2017_V32_MC_Uncertainty_AK4PFPuppi:\")\n",
    "print(type(evaluator['Fall17_17Nov2017_V32_MC_Uncertainty_AK4PFPuppi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jec_out = evaluator['Fall17_17Nov2017_V32_MC_L2Relative_AK4PFPuppi'](events.Jet.eta, events.Jet.pt)\n",
    "junc_out = evaluator['Fall17_17Nov2017_V32_MC_Uncertainty_AK4PFPuppi'](events.Jet.eta, events.Jet.pt)\n",
    "print(\"Correction factor:\", jec_out)\n",
    "# junc_out is a double-jagged array, with the last index being the up, down values\n",
    "# they can be separated via indexing, e.g.:\n",
    "print(\"Uncertainty +:\", junc_out[:, :, 0])\n",
    "print(\"Uncertainty -:\", junc_out[:, :, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying energy scale transformations to Jets\n",
    "\n",
    "The `coffea.jetmet_tools` package provides a convenience class [JetTransformer](https://coffeateam.github.io/coffea/api/coffea.jetmet_tools.JetTransformer.html#coffea.jetmet_tools.JetTransformer) which applies specified corrections and computes uncertainties in one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "from coffea.jetmet_tools import FactorizedJetCorrector, JetCorrectionUncertainty\n",
    "from coffea.jetmet_tools import JetTransformer\n",
    "\n",
    "ext = extractor()\n",
    "ext.add_weight_sets([\n",
    "    \"* * data/Fall17_17Nov2017_V32_MC_L2Relative_AK4PFPuppi.jec.txt\",\n",
    "    \"* * data/Fall17_17Nov2017_V32_MC_Uncertainty_AK4PFPuppi.junc.txt\",\n",
    "])\n",
    "ext.finalize()\n",
    "\n",
    "evaluator = ext.make_evaluator()\n",
    "\n",
    "print(dir(evaluator))\n",
    "print()\n",
    "\n",
    "jets = JaggedCandidateArray.candidatesfromcounts(\n",
    "    events.Jet.counts,\n",
    "    pt=(events.Jet.pt * (1 - events.Jet.rawFactor)).flatten(),\n",
    "    eta=events.Jet.y.flatten(),\n",
    "    phi=events.Jet.z.flatten(),\n",
    "    mass=(events.Jet.mass * (1 - events.Jet.rawFactor)).flatten(),\n",
    ")\n",
    "jets.add_attributes(ptRaw=jets.pt, massRaw=jets.mass)\n",
    "\n",
    "corrector = FactorizedJetCorrector(\n",
    "    Fall17_17Nov2017_V32_MC_L2Relative_AK4PFPuppi=evaluator['Fall17_17Nov2017_V32_MC_L2Relative_AK4PFPuppi'],\n",
    ")\n",
    "uncertainties = JetCorrectionUncertainty(\n",
    "    Fall17_17Nov2017_V32_MC_Uncertainty_AK4PFPuppi=evaluator['Fall17_17Nov2017_V32_MC_Uncertainty_AK4PFPuppi']\n",
    ")\n",
    "\n",
    "transformer = JetTransformer(jec=corrector, junc=uncertainties)\n",
    "### more possibilities are available if you send in more pieces of the JEC stack\n",
    "# mc2016_ak8_jxform = JetTransformer(jec=MC_AK8JEC2016,junc=MC_AK8JUNC2016\n",
    "#                                    jer=MC_AK8JER2016,jersf=MC_AK8JERSF2016)\n",
    "\n",
    "print()\n",
    "print('starting columns:',jets.columns)\n",
    "print()\n",
    "\n",
    "print('untransformed pt ratios',jets.pt/jets.ptRaw)\n",
    "print('untransformed mass ratios',jets.mass/jets.massRaw)\n",
    "\n",
    "transformer.transform(jets)\n",
    "\n",
    "print('transformed pt ratios',jets.pt/jets.ptRaw)\n",
    "print('transformed mass ratios',jets.mass/jets.massRaw)\n",
    "\n",
    "print()\n",
    "print('transformed columns:',jets.columns)\n",
    "print()\n",
    "\n",
    "print('JES UP pt ratio',jets.pt_jes_up/jets.ptRaw)\n",
    "print('JES DOWN pt ratio',jets.pt_jes_down/jets.ptRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying CMS b-tagging corrections\n",
    "The `coffea.btag_tools` module provides the high-level utility [BTagScaleFactor](https://coffeateam.github.io/coffea/api/coffea.btag_tools.BTagScaleFactor.html#coffea.btag_tools.BTagScaleFactor) which calculates per-jet weights for b-tagging as well as light flavor mis-tagging efficiencies. Uncertainties can be calculated as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.btag_tools import BTagScaleFactor\n",
    "\n",
    "btag_sf = BTagScaleFactor(\"data/DeepCSV_102XSF_V1.btag.csv.gz\", \"medium\")\n",
    "\n",
    "print(\"SF:\", btag_sf.eval(\"central\", events.Jet.hadronFlavour, abs(events.Jet.eta), events.Jet.pt))\n",
    "print(\"systematic +:\", btag_sf.eval(\"up\", events.Jet.hadronFlavour, abs(events.Jet.eta), events.Jet.pt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea-hats",
   "language": "python",
   "name": "coffea-hats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
